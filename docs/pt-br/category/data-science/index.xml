<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data Science | Bruno Messias</title><link>/pt-br/category/data-science/</link><atom:link href="/pt-br/category/data-science/index.xml" rel="self" type="application/rss+xml"/><description>Data Science</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>pt-br</language><copyright>Bruno Messias</copyright><lastBuildDate>Mon, 18 Apr 2022 00:00:00 +0000</lastBuildDate><image><url>/images/icon_hucd6a3d413e7b81060a1d462b35f64cf9_5018_512x512_fill_lanczos_center_2.png</url><title>Data Science</title><link>/pt-br/category/data-science/</link></image><item><title>Grafos e modelo de blocos aninhados para matrizes de correla√ß√£o: clusteriza√ß√£o do mercado de a√ß√µes</title><link>/pt-br/post/nsbm_sp500_stock_market_disparity_filter/</link><pubDate>Mon, 18 Apr 2022 00:00:00 +0000</pubDate><guid>/pt-br/post/nsbm_sp500_stock_market_disparity_filter/</guid><description>&lt;details
class="toc-inpage d-print-none d-none d-sm-block d-md-none " open>
&lt;summary class="font-weight-bold">Lista de Conte√∫dos&lt;/summary>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>
&lt;ul>
&lt;li>&lt;a href="#introdu√ß√£o">Introdu√ß√£o&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#grafos">Grafos&lt;/a>&lt;/li>
&lt;li>&lt;a href="#matrizes-de-correla√ß√£o">Matrizes de correla√ß√£o&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#baixando-e-criando-nosso-grafo">Baixando e criando nosso grafo&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#extraindo-o-pre√ßo-de-fechamento">Extraindo o pre√ßo de fechamento&lt;/a>&lt;/li>
&lt;li>&lt;a href="#retorno-e-matrizes-de-correla√ß√£o">Retorno e matrizes de correla√ß√£o&lt;/a>&lt;/li>
&lt;li>&lt;a href="#criando-o-grafo-completo-e-filtrando">Criando o grafo completo e filtrando&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#nsbm-buscando-hierarquia-e-comunidades">nSBM: buscando hierarquia e comunidades&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#convertendo-o-igraph-em-graph-tool">Convertendo o iGraph em graph-tool&lt;/a>&lt;/li>
&lt;li>&lt;a href="#infer√™ncia-dos-blocos">Infer√™ncia dos blocos&lt;/a>&lt;/li>
&lt;li>&lt;a href="#como-analisar">Como analisar?&lt;/a>&lt;/li>
&lt;li>&lt;a href="#outras-aplica√ß√µes-de-nsbm">Outras aplica√ß√µes de nSBM&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#extras-mst">Extras: MST&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#convertendo-correla√ß√µes-em-dist√¢ncias">Convertendo correla√ß√µes em dist√¢ncias&lt;/a>&lt;/li>
&lt;li>&lt;a href="#extraindo-o-mst">Extraindo o MST&lt;/a>&lt;/li>
&lt;li>&lt;a href="#visualizando-o-mst">Visualizando o MST&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#agradecimentos">Agradecimentos&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/details>
&lt;p>Esse post √© da s√©rie sobre filtragem em grafos (esparsifica√ß√£o). O post anterior pode ser acessado em:
&lt;a href="/pt-br/post/edge_graph_filtering/" title="Grafos e filtragem de arestas I: conceitos e confus√µes.">Grafos e filtragem de arestas: conceitos e confus√µes.&lt;/a>&lt;/p>
&lt;p>O objetivo √© mostrar como usar o modelo de bloco estoc√°stico aninhado (nSBM) para o processo de an√°lise explorat√≥ria do mercado de a√ß√µes. O nSBM e SBM s√£o modelos n√£o-param√©tricos estabelecidos numa s√≥lida base estat√≠stica. Vou te ensinar na pr√°tica como usar eles no python e como analisar os outputs, que a primeira vista podem parecer art√≠sticos ou complexos. Veja s√≥:&lt;/p>
&lt;figure >
&lt;a data-fancybox="" href="/pt-br/post/nsbm_sp500_stock_market_disparity_filter/nsbm_final_2018-01-01_2018-06-01_hudcff6362c16284ef400b42c5fe2e1b69_266080_0x500_resize_lanczos_2.png" >
&lt;img data-src="/pt-br/post/nsbm_sp500_stock_market_disparity_filter/nsbm_final_2018-01-01_2018-06-01_hudcff6362c16284ef400b42c5fe2e1b69_266080_0x500_resize_lanczos_2.png" class="lazyload" alt="" width="100%" height="500px">
&lt;/a>
&lt;/figure>
&lt;p>A ordem que seguiremos nesse post √©:&lt;/p>
&lt;ol>
&lt;li>Uma introdu√ß√£o meio longa para te situar em grafos e o porqu√™ usar eles aqui.&lt;/li>
&lt;li>C√≥digo
&lt;ol>
&lt;li>Constru√ß√£o da matriz de correla√ß√£o entre os retornos dos ativos&lt;/li>
&lt;li>Filtragem da matriz de correla√ß√£o via um filtro de grafos&lt;/li>
&lt;li>Infer√™ncia e visualiza√ß√£o do nSBM&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>Como analisar o nSBM?&lt;/li>
&lt;li>Extra: MST&lt;/li>
&lt;/ol>
&lt;p>Para reproduzir esse post recomendo usar um ambiente conda, pois uma das bibliotecas depende de diversas coisas al√©m de libs usais do python&lt;/p>
&lt;p>Comece checando se voc√™ tem as seguintes bibliotecas instaladas&lt;/p>
&lt;pre>&lt;code>matplotlib, pandas, yfinance
&lt;/code>&lt;/pre>
&lt;p>Instale o igraph com&lt;/p>
&lt;pre>&lt;code>$ pip install python-igraph
&lt;/code>&lt;/pre>
&lt;p>O graph-tool, do excelente
&lt;a href="https://twitter.com/tiagopeixoto" target="_blank" rel="noopener">Tiago Peixoto&lt;/a> via conda-forge&lt;/p>
&lt;pre>&lt;code>$ conda install -c conda-forge graph-tool
&lt;/code>&lt;/pre>
&lt;p>N√£o menos importante, voc√™ precisa instalar minha biblioteca de filtragem de grafos, o &lt;code>edgeseraser&lt;/code> deixe seu star
&lt;a href="https://github.com/devmessias/edgeseraser" target="_blank" rel="noopener">aqui&lt;/a> :).&lt;/p>
&lt;pre>&lt;code>$ pip install edgeseraser
&lt;/code>&lt;/pre>
&lt;h2 id="introdu√ß√£o">Introdu√ß√£o&lt;/h2>
&lt;p>An√°lise explorat√≥ria √© usada tanto como o objetivo final em si como uma ferramenta que fornece subs√≠dios para melhores tomadas de decis√µes para escolha de modelos preditivos ou pr√©-sele√ß√£o de inst√¢ncias para serem analisadas com mais detalhes.&lt;/p>
&lt;p>Contudo, muitas das t√©cnicas exploradas e ensinadas na web se restringem √†quelas que podem ser empregadas quando o conjunto de dados vive em algum espa√ßo organizado (como o $\mathbb R^n$) e cujos dados n√£o t√™m rela√ß√£o entre si. Um conjunto de pontos. Mas e os dados que n√£o se enquadram nisso?&lt;/p>
&lt;p>Um exemplo de conjunto de dados extremamente complicado s√£o as redes sociais. Redes sociais s√£o conjuntos de pessoas e a exist√™ncia de pelo menos rela√ß√µes pares a pares (hyper-grafos √© um assunto para outro post) podendo ser negativas, positivas ou algo mais complicado. Cada pessoa em uma rede social pode ser identificada por um conjunto de features tais como gostos pessoais, hor√°rio de uso do sistema, etc. Representar uma rede social por pontinhos √© reducionista. √â para isso que grafos podem ser empregados&lt;/p>
&lt;h3 id="grafos">Grafos&lt;/h3>
&lt;p>Um grafo armazena objetos que t√™m rela√ß√µes pares a pares entre si. Sendo poss√≠vel associar a cada objeto ou rela√ß√£o um outro tipo de dado gen√©rico tais como um n√∫mero real, um vetor ou mesmo outro grafo. Mas √© importante ressaltar que grafos est√£o em todo lugar, por exemplo em matrizes de correla√ß√£o. Portanto, usar grafos para analisar correla√ß√µes √© v√°lido, especialmente quando muitas dessas correla√ß√µes podem ou queremos que sejam descartadas.&lt;/p>
&lt;blockquote class="twitter-tweet">&lt;p lang="pt" dir="ltr">At√© onde j√° estudei, toda estrutura de dados pode ser representada como um grafo. Nesse sentido, podemos dizer que o grafo √© a &amp;quot;m√£e&amp;quot; de todas as estruturas de dados. Talvez dev√™ssemos dar mais foco a grafos nos cursos de EDs.&lt;/p>&amp;mdash; psiquiatra de computadores (üå≥, üå≥) (@coproduto) &lt;a href="https://twitter.com/coproduto/status/1514562359007842310?ref_src=twsrc%5Etfw">April 14, 2022&lt;/a>&lt;/blockquote>
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;h3 id="matrizes-de-correla√ß√£o">Matrizes de correla√ß√£o&lt;/h3>
&lt;p>No &lt;em>OpenCode&lt;/em> matrizes de correla√ß√£o j√° apareceram em diversos posts:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>
&lt;a href="https://opencodecom.net/post/2021-12-14-variacoes-do-teorema-central-do-limite-para-matrizes-aleatorias-de-nucleos-atomicos-a-filtragem-de-matrizes-de-correlaca/" target="_blank" rel="noopener">Varia√ß√µes do teorema central do limite para matrizes aleat√≥rias: de n√∫cleos at√¥micos a filtragem de matrizes de correla√ß√£o para constru√ß√£o de carteiras&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>
&lt;a href="https://opencodecom.net/post/2021-09-01-correlacao-entre-ativos-no-python/" target="_blank" rel="noopener">Correla√ß√£o entre Ativos no Python&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Mas o que √© uma matriz de correla√ß√£o se n√£o um conjunto de rela√ß√µes pares a pares com valores reais? Bom, ent√£o a quest√£o aqui fica evidente: &lt;strong>Uma matriz de correla√ß√£o pode ser analisada usando ferramentas feitas para analisar grafos! Ok, isso pode ser feito, mas voc√™ pode se perguntar o porqu√™ de fazer isso.&lt;/strong>&lt;/p>
&lt;p>Uma atividade muito comum quando exploramos matrizes de correla√ß√£o √© tentar encontrar grupos de elementos fortemente/fracamente correlacionados, isso n√£o √© uma tarefa trivial √† medida que o n√∫mero de elementos aumenta. Al√©m disso, √© comum jogarmos fora as rela√ß√µes que s√£o muito fracas. Quando fazemos isso estamos esparsificando a matriz, na terminologia de grafos estamos filtrando arestas!
&lt;a href="/pt-br/post/edge_graph_filtering/#estrutural-threshold">No post anterior eu discuti o porqu√™ disso poder ser bem perigoso.&lt;/a>.&lt;/p>
&lt;p>Uma maneira mais elaborada de se analisar matrizes de correla√ß√£o √© atrav√©s da constru√ß√£o de
&lt;a href="https://www.youtube.com/watch?v=jMioOe2eTcY" target="_blank" rel="noopener">√°rvores de expans√£o m√≠nima (MST)&lt;/a>, apesar do nome complicado √© um processo bem simples de construir um grafo e voc√™ pode encontrar diversos tutoriais sobre MST e o mercado de a√ß√µes na internet.&lt;/p>
&lt;p>Devido a tutoriais com MST estarem j√° espalhados, decidi fazer algo diferente aqui e propor usar um m√©todo pouco conhecido para explora√ß√£o de grafos e aplicar ele em matrizes de correla√ß√£o de ativos. Esse m√©todo √© conhecido pela sigla &lt;em>nSBM&lt;/em>, modelo de bloco estoc√°stico aninhado (nested Stochastic Block Model) e √© um m√©todo n√£o-param√©trico para infer√™ncia de comunidades em grafos que permite analisar a hierarquia de comunidades.&lt;/p>
&lt;div class="alert alert-">
&lt;div>
No final do post vou mostrar a mesma matriz analisada pelo MST s√≥ para voc√™ ter uma ideia do porqu√™ o nSBM ser bem mais interessante.
&lt;/div>
&lt;/div>
&lt;p>Uma das grandes qualidades dos SBM e variantes √© que eles s√£o constru√≠dos em cima de um arcabou√ßo estat√≠stico rigoroso e ao mesmo tempo √© poss√≠vel detectar comunidades com pouqu√≠ssimos v√©rtices. Isso √© √≥timo, pois duas coisas que n√£o queremos √© que o m√©todo que escolhamos diga que certas coisas formam comunidades mesmo que n√£o passe de um amontoado de coisas aleat√≥rias e que ele bote coisas onde n√£o devia s√≥ porque s√£o pequenas demais, &lt;strong>isso √© uma cr√≠tica aos m√©todos de detec√ß√£o por maximiza√ß√£o de modularidade&lt;/strong>&lt;/p>
&lt;h2 id="baixando-e-criando-nosso-grafo">Baixando e criando nosso grafo&lt;/h2>
&lt;h3 id="extraindo-o-pre√ßo-de-fechamento">Extraindo o pre√ßo de fechamento&lt;/h3>
&lt;p>Vamos come√ßar importando o que for necess√°rio&lt;/p>
&lt;pre>&lt;code class="language-python">import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
import igraph as ig
from edgeseraser.disparity import filter_ig_graph
mpl.rcParams.update(_VSCode_defaultMatplotlib_Params)
plt.style.context('classic')
mpl.rcParams['figure.facecolor'] = 'white'
&lt;/code>&lt;/pre>
&lt;p>Usaremos uma tabela contendo os simbolos de um conjunto de ativos e os setores. O csv tem a seguinte organiza√ß√£o, e est√° dispon√≠vel
&lt;a href="https://raw.githubusercontent.com/datasets/s-and-p-500-companies/master/data/constituents.csv" target="_blank" rel="noopener">aqui&lt;/a>.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Symbol&lt;/th>
&lt;th>Name&lt;/th>
&lt;th>Sector&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>MMM&lt;/td>
&lt;td>3M&lt;/td>
&lt;td>Industrials&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>AOS&lt;/td>
&lt;td>A. O. Smith&lt;/td>
&lt;td>Industrials&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ABT&lt;/td>
&lt;td>Abbott Laboratories&lt;/td>
&lt;td>Health Care&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ABBV&lt;/td>
&lt;td>AbbVie&lt;/td>
&lt;td>Health Care&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;pre>&lt;code class="language-python">!wget https://raw.githubusercontent.com/datasets/s-and-p-500-companies/master/data/constituents.csv
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-python">df = pd.read_csv(&amp;quot;constituents.csv&amp;quot;)
all_symbols = df['Symbol'].values
all_sectors = df['Sector'].values
all_names = df['Name'].values
# Criaremos um dicion√°rio para mapear um simbolo para seu
# setor e uma cor
symbol2sector = dict(zip(all_symbols, all_sectors))
symbol2name = dict(zip(all_symbols, all_names))
&lt;/code>&lt;/pre>
&lt;p>Hora de baixar as informa√ß√µes sobre os ativos. Iremos computar as correla√ß√µes numa janela de um semestre.&lt;/p>
&lt;pre>&lt;code class="language-python">start_date = '2018-01-01'
end_date = '2018-06-01'
try:
prices = pd.read_csv(
f&amp;quot;sp500_prices_{start_date}_{end_date}.csv&amp;quot;, index_col=&amp;quot;Date&amp;quot;)
tickers_available = prices.columns.values
except FileNotFoundError:
df = yf.download(
list(all_symbols),
start=start_date,
end=end_date,
interval=&amp;quot;1d&amp;quot;,
group_by='ticker',
progress=True
)
tickers_available = list(
set([ticket for ticket, _ in df.columns.T.to_numpy()]))
prices = pd.DataFrame.from_dict(
{
ticker: df[ticker][&amp;quot;Adj Close&amp;quot;].to_numpy()
for ticker in tickers_available
}
)
prices.index = df.index
prices = prices.iloc[:-1]
del df
prices.to_csv(
f&amp;quot;sp500_prices_{start_date}_{end_date}.csv&amp;quot;)
&lt;/code>&lt;/pre>
&lt;h3 id="retorno-e-matrizes-de-correla√ß√£o">Retorno e matrizes de correla√ß√£o&lt;/h3>
&lt;p>A correla√ß√£o ser√° calculada para todos os ativos considerando o retorno. O retorno que estamos calculando aqui √© simplesmente a mudan√ßa percentual do pre√ßo de fechamento do ativo.&lt;/p>
&lt;pre>&lt;code class="language-python">returns_all = prices.pct_change()
# a primeira linha n√£o faz sentido, n√£o existe retorno no primeiro dia
returns_all = returns_all.iloc[1:, :]
returns_all.dropna(axis=1, thresh=len(returns_all.index)//2., inplace=True)
returns_all.dropna(axis=0, inplace=True)
symbols = returns_all.columns.values
&lt;/code>&lt;/pre>
&lt;p>Para calcular a correla√ß√£o √© f√°cil&lt;/p>
&lt;pre>&lt;code class="language-python"># plot the correlation matrix with ticks at each item
correlation_matrix = returns_all.corr()
plt.title(f&amp;quot;Correlation matrix from {start_date} to {end_date}&amp;quot;)
plt.imshow(correlation_matrix)
plt.colorbar()
plt.savefig(&amp;quot;correlation.png&amp;quot;, dpi=150)
plt.clf()
&lt;/code>&lt;/pre>
&lt;figure id="figure-matriz-de-correla√ß√£o-entre-ativos-do-sp500-para-o-primeiro-semestre-de-2018-sim-uma-bagun√ßa">
&lt;a data-fancybox="" href="/pt-br/post/nsbm_sp500_stock_market_disparity_filter/correlation_hu6c68fc9d1aa2b5f7307017b57ffa4d90_521823_0x500_resize_lanczos_2.png" data-caption="Matriz de correla√ß√£o entre ativos do s&amp;amp;amp;p500 para o primeiro semestre de 2018. Sim, uma bagun√ßa!">
&lt;img data-src="/pt-br/post/nsbm_sp500_stock_market_disparity_filter/correlation_hu6c68fc9d1aa2b5f7307017b57ffa4d90_521823_0x500_resize_lanczos_2.png" class="lazyload" alt="" width="100%" height="500px">
&lt;/a>
&lt;figcaption>
Matriz de correla√ß√£o entre ativos do s&amp;amp;p500 para o primeiro semestre de 2018. Sim, uma bagun√ßa!
&lt;/figcaption>
&lt;/figure>
&lt;p>Ok, voc√™ seria louco de analisar essa matriz manualmente. Vamos partir para o motivo desse post que √© usar nSBM.&lt;/p>
&lt;h3 id="criando-o-grafo-completo-e-filtrando">Criando o grafo completo e filtrando&lt;/h3>
&lt;p>Como queremos explorar as comunidades usaremos apenas as correla√ß√µes positivas,&lt;/p>
&lt;pre>&lt;code class="language-python">pos_correlation = correlation_matrix.copy()
# vamos considerar apenas as correla√ß√µes positivas pois queremos
# apenas as comunidades
pos_correlation[pos_correlation &amp;lt; 0.] = 0
# diagonal principal √© setada a 0 para evitar auto-arestas
np.fill_diagonal(pos_correlation.values, 0)
&lt;/code>&lt;/pre>
&lt;p>Agora basta construir o grafo n√£o direcionado associando os pesos das arestas com a correla√ß√£o entre os ativos.&lt;/p>
&lt;pre>&lt;code class="language-python">g = ig.Graph.Weighted_Adjacency(pos_correlation.values, mode='undirected')
# criamos uma feature symbol para cada v√©rtice
g.vs[&amp;quot;symbol&amp;quot;] = returns_all.columns
# o grafo pode estar desconectado. Portanto, extra√≠mos a componente gigante
cl = g.clusters()
g = cl.giant()
n_edges_before = g.ecount()
&lt;/code>&lt;/pre>
&lt;p>Agora iremos aplicar o
&lt;a href="/pt-br/post/edge_graph_filtering/#estatistico" title="Grafos e filtragem de arestas I: conceitos e confus√µes. Filtro estat√≠stico">filtro de disparidade&lt;/a>
do edgeseraser para remover as arestas que n√£o s√£o significativas&lt;/p>
&lt;pre>&lt;code class="language-python">_ = filter_ig_graph(g, .25, cond=&amp;quot;both&amp;quot;, field=&amp;quot;weight&amp;quot;)
cl = g.clusters()
g = cl.giant()
n_edges_after = g.ecount()
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-python">print(f&amp;quot;Percentage of edges removed: {(n_edges_before - n_edges_after)/n_edges_before*100:.2f}%&amp;quot;)
print(f&amp;quot;Number of remained stocks: {len(symbols)}&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>Percentage of edges removed: 95.76%
Number of remained stocks: 492
&lt;/code>&lt;/pre>
&lt;p>A maior parte das arestas foi removida. Ser√° que conseguimos fazer algo com esse grafo compactado?&lt;/p>
&lt;h2 id="nsbm-buscando-hierarquia-e-comunidades">nSBM: buscando hierarquia e comunidades&lt;/h2>
&lt;h3 id="convertendo-o-igraph-em-graph-tool">Convertendo o iGraph em graph-tool&lt;/h3>
&lt;p>O graph-tool √© um pacote com excelente desempenho, mas para ganhar essa performance ele
exige um pouquinho mais de trabalho tais como declarar o tipo dos dados. O primeiro
passo para usar o graph-tool √© converter nosso grafo iGraph para uma inst√¢ncia dele&lt;/p>
&lt;pre>&lt;code class="language-python">import graph_tool.all as gt
gnsbm = gt.Graph(directed=False)
# iremos adicionar os v√©rtices
for v in g.vs:
gnsbm.add_vertex()
# e as arestas
for e in g.es:
gnsbm.add_edge(e.source, e.target)
&lt;/code>&lt;/pre>
&lt;h3 id="infer√™ncia-dos-blocos">Infer√™ncia dos blocos&lt;/h3>
&lt;p>Com o grafo constru√≠do iremos executar o algoritmo de infer√™ncia de blocos.
Esse algoritmo executa uma minimiza√ß√£o do que √© conhecido como &lt;em>&amp;ldquo;description length&amp;rdquo;&lt;/em> do modelo Bayesiano. Em um post futuro falarei um pouco sobre a matem√°tica se voc√™ se j√° estiver interessado d√™ uma olhada no artigo original do Tiago Peixoto
&lt;a href="https://dx.doi.org/10.1103/PhysRevX.4.011047" target="_blank" rel="noopener">aqui&lt;/a>.&lt;/p>
&lt;pre>&lt;code class="language-python">state = gt.minimize_nested_blockmodel_dl(gnsbm)
&lt;/code>&lt;/pre>
&lt;p>O c√≥digo abaixo √© s√≥ para gerar as cores para nosso plot&lt;/p>
&lt;pre>&lt;code class="language-python">symbols = g.vs[&amp;quot;symbol&amp;quot;]
sectors = [symbol2sector[symbol] for symbol in symbols]
u_sectors = np.sort(np.unique(sectors))
u_colors = [plt.cm.tab10(i/len(u_sectors))
for i in range(len(u_sectors))]
# a primeira cor da lista era muito similar a segunda,
u_colors[0] = [0, 1, 0, 1]
sector2color = {sector: color for sector, color in zip(u_sectors, u_colors)}
rgba = gnsbm.new_vertex_property(&amp;quot;vector&amp;lt;double&amp;gt;&amp;quot;)
gnsbm.vertex_properties['rgba'] = rgba
for i, symbol in enumerate(symbols):
c = sector2color[symbol2sector[symbol]]
rgba[i] = [c[0], c[1], c[2], .5]
&lt;/code>&lt;/pre>
&lt;p>Executaremos o m√©todo draw para gerar o plot. O par√¢metro que talvez voc√™ queira brincar um pouco √© o $\beta \in (0, 1)$. Tal par√¢metro √© respons√°vel pela for√ßa do &lt;strong>edge-bundling&lt;/strong>, ou seja, a for√ßa com que as arestas ser√£o atra√≠das uma √† outra. Este par√¢metro tem finalidades apenas para facilitar a visualiza√ß√£o, n√£o existe nenhuma rela√ß√£o com o nSBM.&lt;/p>
&lt;pre>&lt;code class="language-python">options = {
'output': f'nsbm_{start_date}_{end_date}.png',
'beta': .9,
'bg_color': 'w',
#'output_size': (1500, 1500),
'vertex_color': gnsbm.vertex_properties['rgba'],
'vertex_fill_color': gnsbm.vertex_properties['rgba'],
'hedge_pen_width': 2,
'hvertex_fill_color': np.array([0., 0., 0., .5]),
'hedge_color': np.array([0., 0., 0., .5]),
'hedge_marker_size': 20,
'hvertex_size':20
}
state.draw(**options)
&lt;/code>&lt;/pre>
&lt;p>Finalmente, agora √© s√≥ ver o resultado da nossa filtragem e infer√™ncia&lt;/p>
&lt;pre>&lt;code class="language-python">plt.figure(dpi=150)
plt.title(f&amp;quot;Sectors of the S&amp;amp;P 500 from {start_date} to {end_date}&amp;quot;)
legend = plt.legend(
[plt.Line2D([0], [0], color=c, lw=10)
for c in list(sector2color.values())],
list(sector2color.keys()),
bbox_to_anchor=(1.05, 1),
loc=2,
borderaxespad=0.)
plt.imshow(plt.imread(f'nsbm_{start_date}_{end_date}.png'))
plt.xticks([])
plt.yticks([])
plt.axis('off')
plt.savefig(f'nsbm_final_{start_date}_{end_date}.png', bbox_inches='tight',
dpi=150, bbox_extra_artists=(legend,), facecolor='w', edgecolor='w')
plt.show()
&lt;/code>&lt;/pre>
&lt;figure id="figure-resultado-do-modelo-de-blocos-aninhados-para-o-primeiro-semestre-de-2018-de-ativos-do-sp500-art√≠stico">
&lt;a data-fancybox="" href="/pt-br/post/nsbm_sp500_stock_market_disparity_filter/nsbm_final_2018-01-01_2018-06-01_hudcff6362c16284ef400b42c5fe2e1b69_266080_0x500_resize_lanczos_2.png" data-caption="Resultado do modelo de blocos aninhados para o primeiro semestre de 2018 de ativos do s&amp;amp;amp;p500. Art√≠stico?">
&lt;img data-src="/pt-br/post/nsbm_sp500_stock_market_disparity_filter/nsbm_final_2018-01-01_2018-06-01_hudcff6362c16284ef400b42c5fe2e1b69_266080_0x500_resize_lanczos_2.png" class="lazyload" alt="" width="100%" height="500px">
&lt;/a>
&lt;figcaption>
Resultado do modelo de blocos aninhados para o primeiro semestre de 2018 de ativos do s&amp;amp;p500. Art√≠stico?
&lt;/figcaption>
&lt;/figure>
&lt;p>Ok, muito bonito! Conseguimos ver agrupamentos de certos setores, algumas misturas, muitas conex√µes entre o &lt;em>Financials&lt;/em> e &lt;em>Industrials&lt;/em>, etc. Se voc√™ n√£o consegue ver isso agora vou tentar te explicar como interpretar esse gr√°fico.&lt;/p>
&lt;h3 id="como-analisar">Como analisar?&lt;/h3>
&lt;figure >
&lt;a data-fancybox="" href="/pt-br/post/nsbm_sp500_stock_market_disparity_filter/descripition_nsbm_sp500_hufe6166112f10aa58541f55447fe95bbb_1458779_0x500_resize_lanczos_2.png" >
&lt;img data-src="/pt-br/post/nsbm_sp500_stock_market_disparity_filter/descripition_nsbm_sp500_hufe6166112f10aa58541f55447fe95bbb_1458779_0x500_resize_lanczos_2.png" class="lazyload" alt="" width="100%" height="500px">
&lt;/a>
&lt;/figure>
&lt;ul>
&lt;li>Cada c√≠rculo no conjunto que parece a escova de uma vassoura √© um ativo, um v√©rtice do grafo original.&lt;/li>
&lt;li>Cada escova √© uma comunidade de ativos. Podemos navegar na hierarquia seguindo o caminho reverso apontado pelas setinhas no grafo em preto. Veja que na imagem eu coloquei como exemplo tr√™s comunidades que pertencem √† mesma comunidade pai.
Uma coisa interessante que podemos observar √© que a maior parte dos ativos relacionados a &lt;strong>Consumer staples&lt;/strong> forma uma comunidade com &lt;strong>Real state&lt;/strong> e &lt;strong>Utilities&lt;/strong> no segundo n√≠vel.&lt;/li>
&lt;/ul>
&lt;p>E as arestas?&lt;/p>
&lt;ul>
&lt;li>Podemos notar que um grande n√∫mero de conex√µes entre &lt;strong>Financials&lt;/strong>, &lt;strong>Industrials&lt;/strong> e &lt;strong>Information technology&lt;/strong> sobreviveram ao filtro de disparidade. Sendo um indicativo que esses ativos t√™m uma forte rela√ß√£o nos retornos.
Ok, antes eu falei que o $\beta$ controla o efeito de atra√ß√£o entre as arestas, veja o que acontece se eu reduzir o $\beta$ para $0.5$:&lt;/li>
&lt;/ul>
&lt;figure id="figure-horr√≠vel-n√£o-√©-mesmo">
&lt;a data-fancybox="" href="/pt-br/post/nsbm_sp500_stock_market_disparity_filter/nsbm_2018-01-01_2018-06-01_beta_0.5_hu63a031e361e4cd7a15f51f9db9995b63_1589031_0x400_resize_lanczos_2.png" data-caption="Horr√≠vel n√£o √© mesmo?">
&lt;img src="/pt-br/post/nsbm_sp500_stock_market_disparity_filter/nsbm_2018-01-01_2018-06-01_beta_0.5_hu63a031e361e4cd7a15f51f9db9995b63_1589031_0x400_resize_lanczos_2.png" alt="" height="400px">
&lt;/a>
&lt;figcaption>
Horr√≠vel n√£o √© mesmo?
&lt;/figcaption>
&lt;/figure>
&lt;p>Voc√™ tamb√©m pode explorar o resultado do nSBM manualmente. Para obter um sum√°rio da hierarquia das comunidades obtidas pelo nSBM podemos invocar o m√©todo &lt;code>print_summary&lt;/code>&lt;/p>
&lt;pre>&lt;code class="language-python">state.print_summary()
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>l: 0, N: 483, B: 25
l: 1, N: 25, B: 6
l: 2, N: 6, B: 2
l: 3, N: 2, B: 1
l: 4, N: 1, B: 1
&lt;/code>&lt;/pre>
&lt;p>No n√≠vel de folhas temos os ativos. No primeiro n√≠vel temos &lt;strong>21&lt;/strong> comunidades para os &lt;strong>11&lt;/strong> setores.&lt;/p>
&lt;p>Supondo que voc√™ queira obter quais comunidades um dado ativo pertence, no caso &amp;ldquo;TSLA&amp;rdquo;,&lt;/p>
&lt;pre>&lt;code class="language-python"># esse √© o indice da TSLA no nosso grafo original
symbol = &amp;quot;TSLA&amp;quot;
index_tesla = symbols.index(symbol)
symbol, symbol2sector[symbol], symbol2name[symbol]
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>('TSLA', 'Consumer Discretionary', 'Tesla')
&lt;/code>&lt;/pre>
&lt;p>Para obter as comunidades que o TSLA pertence percorremos a hierarquia de baixo para cima, at√© a raiz&lt;/p>
&lt;pre>&lt;code class="language-python"># para obter os indices
r0 = state.levels[0].get_blocks()[index_tesla]
r1 = state.levels[1].get_blocks()[r0]
r2 = state.levels[2].get_blocks()[r1]
r3 = state.levels[3].get_blocks()[r2]
(r1, r2, r3)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>(19, 0, 0)
&lt;/code>&lt;/pre>
&lt;p>Voc√™ pode explorar as comunidades usando essa abordagem. Contudo, eu recomendo voc√™ usar o THREE.js ou D3 para realizar essa explora√ß√£o. Futuramente disponibilizarei meu c√≥digo para permitir uma visualiza√ß√£o interativa do nsbm usando threejs direto no browser!&lt;/p>
&lt;h3 id="outras-aplica√ß√µes-de-nsbm">Outras aplica√ß√µes de nSBM&lt;/h3>
&lt;p>nSBM&amp;rsquo;s e SBM&amp;rsquo;s encontram diversas aplica√ß√µes como
&lt;a href="https://www.science.org/doi/10.1126/sciadv.aaq1360" target="_blank" rel="noopener">NLP&lt;/a> e em um trabalho recente meu em an√°lise de
&lt;a href="https://arxiv.org/abs/2110.01421" target="_blank" rel="noopener">surveys&lt;/a>.
&lt;figure id="figure-um-jaba-pr√≥prio-nsbm-do-censo-escolar-pense">
&lt;a data-fancybox="" href="/pt-br/post/nsbm_sp500_stock_market_disparity_filter/allDummyAUC_alpha=0-05_hu1c20d905c5634e6a84f02ee440a1f7e5_1616945_0x400_resize_lanczos_2.png" data-caption="Um jaba pr√≥prio. nSBM do censo escolar PeNSE.">
&lt;img src="/pt-br/post/nsbm_sp500_stock_market_disparity_filter/allDummyAUC_alpha=0-05_hu1c20d905c5634e6a84f02ee440a1f7e5_1616945_0x400_resize_lanczos_2.png" alt="" height="400px">
&lt;/a>
&lt;figcaption>
Um jaba pr√≥prio. nSBM do censo escolar PeNSE.
&lt;/figcaption>
&lt;/figure>
&lt;/p>
&lt;h2 id="extras-mst">Extras: MST&lt;/h2>
&lt;p>Eu prometi mostrar como ficaria o mesmo universo de dados usando MST (√°rvores de expans√£o m√≠nima). A intui√ß√£o por tr√°s do MST √© que queremos construir um grafo esparso de um grafo original, tal que as somas dos pesos das arestas seja a menor poss√≠vel sem desconectar os v√©rtices do grafo. Veja mais aprofundado
&lt;a href="https://hudsonthames.org/networks-with-mlfinlab-minimum-spanning-tree-mst/" target="_blank" rel="noopener">aqui&lt;/a>.&lt;/p>
&lt;h3 id="convertendo-correla√ß√µes-em-dist√¢ncias">Convertendo correla√ß√µes em dist√¢ncias&lt;/h3>
&lt;p>A primeira coisa que precisamos fazer √© converter a matriz de correla√ß√£o em uma matriz de dist√¢ncia. Isso pode ser feito usando a seguinte fun√ß√£o&lt;/p>
&lt;p>$d(\mathrm{stock}_1, \mathrm{stock}_2) = \sqrt{2(1-\mathrm{corr}(\mathrm{stock_1}, \mathrm{stock}_2))}$&lt;/p>
&lt;pre>&lt;code class="language-python">dist_matrix = np.sqrt(2*(1-correlation_matrix))
dist_matrix = dist_matrix.fillna(0)
np.fill_diagonal(dist_matrix.values, 0)
&lt;/code>&lt;/pre>
&lt;h3 id="extraindo-o-mst">Extraindo o MST&lt;/h3>
&lt;p>O &lt;code>igraph&lt;/code> j√° implementa um algoritmo para extrair o MST de um grafo de forma eficiente, mesmo que o grafo seja completo. Nossa matriz de correla√ß√£o √© um grafo completo!&lt;/p>
&lt;pre>&lt;code class="language-python">
g = ig.Graph.Weighted_Adjacency(dist_matrix.values, mode='undirected')
g = g.spanning_tree(weights=&amp;quot;weight&amp;quot;, return_tree=True)
g.vs[&amp;quot;symbol&amp;quot;] = returns_all.columns
sectors = [symbol2sector[symbol] for symbol in returns_all.columns]
colors = [
sector2color[sector] for sector in sectors
]
&lt;/code>&lt;/pre>
&lt;h3 id="visualizando-o-mst">Visualizando o MST&lt;/h3>
&lt;p>Agora com nosso MST vamos usar um layout de grafos bem simples para visualizar nosso grafo&lt;/p>
&lt;pre>&lt;code class="language-python">g.vs[&amp;quot;color&amp;quot;] = colors
pos = g.layout_fruchterman_reingold(niter=10000, weights=&amp;quot;weight&amp;quot;)
pos = np.array(pos.coords)
&lt;/code>&lt;/pre>
&lt;p>Finalmente, nosso resultado:&lt;/p>
&lt;pre>&lt;code class="language-python">from matplotlib.collections import LineCollection
lines = []
colors = []
for s, t in g.get_edgelist():
x0, y0 = pos[s]
x1, y1 = pos[t]
lines.append([(x0, y0), (x1, y1)])
colors.append(&amp;quot;black&amp;quot;)
lc = LineCollection(lines, colors=colors, zorder=0, alpha=.5)
fig = plt.figure(figsize=(10, 10))
ax = fig.add_subplot(1, 1, 1)
ax.scatter(
pos[:, 0],
pos[:, 1],
c=g.vs[&amp;quot;color&amp;quot;],
s=25,
marker=&amp;quot;d&amp;quot;,
alpha=.8,
zorder=1
)
ax.add_collection(lc)
ax.axis('off')
legend = ax.legend(
[plt.Line2D([0], [0], color=c, lw=10)
for c in list(sector2color.values())],
list(sector2color.keys()),
bbox_to_anchor=(1.05, 1),
loc=2,
borderaxespad=0.)
plt.savefig(f'mst_{start_date}_{end_date}.png', bbox_inches='tight',)
plt.show()
&lt;/code>&lt;/pre>
&lt;figure id="figure-mst-para-ativos-do-sp500-no-primeiro-semestre-de-2018">
&lt;a data-fancybox="" href="/pt-br/post/nsbm_sp500_stock_market_disparity_filter/mst_2018-01-01_2018-06-01_huc06590f539d2bf35f6546a367d158c6d_73932_0x500_resize_lanczos_2.png" data-caption="MST para ativos do S&amp;amp;amp;P500 no primeiro semestre de 2018">
&lt;img data-src="/pt-br/post/nsbm_sp500_stock_market_disparity_filter/mst_2018-01-01_2018-06-01_huc06590f539d2bf35f6546a367d158c6d_73932_0x500_resize_lanczos_2.png" class="lazyload" alt="" width="100%" height="500px">
&lt;/a>
&lt;figcaption>
MST para ativos do S&amp;amp;P500 no primeiro semestre de 2018
&lt;/figcaption>
&lt;/figure>
&lt;p>Alguns padr√µes aparecem, mas o MST √© muito menos rico de informa√ß√µes que o nSBM, exploraremos mais essas vantagens em posts futuros.&lt;/p>
&lt;h2 id="agradecimentos">Agradecimentos&lt;/h2>
&lt;p>Agrade√ßo ao
&lt;a href="https://www.linkedin.com/in/maikereis/" target="_blank" rel="noopener">Maike Reis&lt;/a> e
&lt;a href="https://www.linkedin.com/in/felipe-alves-dos-santos/" target="_blank" rel="noopener">Felipe Santos&lt;/a> pelas dicas e corre√ß√µes.&lt;/p></description></item><item><title>Varia√ß√µes do teorema central do limite para matrizes aleat√≥rias.</title><link>/pt-br/post/random_matrix_portfolio/</link><pubDate>Mon, 06 Dec 2021 00:00:00 +0000</pubDate><guid>/pt-br/post/random_matrix_portfolio/</guid><description>&lt;blockquote>
&lt;p>Dispon√≠vel em
&lt;a href="https://opencodecom.net/post/2021-12-14-variacoes-do-teorema-central-do-limite-para-matrizes-aleatorias-de-nucleos-atomicos-a-filtragem-de-matrizes-de-correlaca/" target="_blank" rel="noopener">https://opencodecom.net/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>No c√©lebre trabalho ‚Äú&lt;em>Can One Hear the Shape of a Drum?&lt;/em>‚Äù[1] Kack questiona se conhecendo o espectro (&lt;em>som&lt;/em>) de um certo operador que define as oscila√ß√µes de uma membrana (&lt;em>tambor&lt;/em>) seria poss√≠vel identificar o formato de tal membrana de maneira un√≠voca. Discutiremos aqui como √© poss√≠vel ouvir matrizes de correla√ß√£o usando seu espectro e como podemos remover o ru√≠do desse som usando resultados da teoria de matrizes aleat√≥rias. Veremos como essa filtragem pode aprimorar algoritmos de constru√ß√£o de carteiras de investimentos.&lt;/p>
&lt;blockquote>
&lt;p>Minhas motiva√ß√µes para escrever esse texto foram o movimento
&lt;a href="https://twitter.com/sseraphini/status/1458169250326142978" target="_blank" rel="noopener">Learn In Public-Sibelius Seraphini&lt;/a> e o Nobel de F√≠sica de 2021. Um dos temas de Giorgio Parisi √© o estudo de matrizes aleat√≥rias
&lt;a href="https://www.nobelprize.org/uploads/2021/10/sciback_fy_en_21.pdf" target="_blank" rel="noopener">www.nobelprize.org 2021&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;p>..&lt;/p>
&lt;blockquote>
&lt;p>Jupyter notebook dispon√≠vel
&lt;a href="https://github.com/devmessias/devmessias.github.io/blob/master/content/post/random_matrix_portfolio/index.ipynb" target="_blank" rel="noopener">aqui&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h1 id="1-introdu√ß√£o-teorema-central-do-limite">1-Introdu√ß√£o: teorema central do limite&lt;/h1>
&lt;p>O teorema central do limite est√° no cora√ß√£o da an√°lise estat√≠stica. Em poucas palavras o mesmo estabelece o seguinte.&lt;/p>
&lt;blockquote>
&lt;p>Suponha uma amostra $A = (x_1, x_2, \dots, x_n)$ de uma vari√°vel aleat√≥ria com m√©dia $\mu$ e vari√¢ncia $\sigma^2$ finita. Se a amostragem √© $i.i.d.$ o teorema central do limite estabelece que a
distribui√ß√£o de probababilidade da m√©dia amostral converge
para uma distribui√ß√£o normal com vari√¢ncia $\sigma^2/n$ e m√©dia $\mu$ a medida que $n$ aumenta.&lt;/p>
&lt;/blockquote>
&lt;p>Note que eu n√£o disse nada a respeito de como tal amostra foi gerada; em nenhum momento citei distribui√ß√£o de Bernoulli, Gauss, Poisson, etc. Desta maneira podemos dizer que tal converg√™ncia √© uma propriedade &lt;strong>universal&lt;/strong> de amostras aleat√≥rias $i.i.d.$. Essa universalidade √© poderosa, pois garante que √© poss√≠vel estimar a m√©dia e vari√¢ncia de uma popula√ß√£o atrav√©s de um conjunto de amostragens.&lt;/p>
&lt;p>N√£o √© dif√≠cil fazer um experimento computacional onde a implica√ß√£o desse teorema apare√ßa&lt;/p>
&lt;pre>&lt;code class="language-python">import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import warnings
from matplotlib import style
warnings.filterwarnings('ignore')
style.use('seaborn-white')
np.random.seed(22)
&lt;/code>&lt;/pre>
&lt;p>Usaremos uma amostragem de uma distribui√ß√£o exponencial com m√©dia $\mu = 4$. Tal distribui√ß√£o tem uma vari√¢ncia dada por $1/\mu^2$. Faremos $10000$ experimentos com amostras de tamanho $500$. Posteriormente calcularemos a media de cada experimento, &lt;code>mean_by_exp&lt;/code>&lt;/p>
&lt;pre>&lt;code class="language-python">rate = 0.25
mu = 1/rate
sample_size=500
exponential_sample = np.random.exponential(mu, size=(sample_size, 30000))
mean_by_exp = exponential_sample.mean(axis=0)
&lt;/code>&lt;/pre>
&lt;p>Agora basta plotar o histograma em compara√ß√£o com a distribui√ß√£o normal dada pelo teorema central do limite&lt;/p>
&lt;pre>&lt;code class="language-python">sns.distplot(mean_by_exp, norm_hist=True, label='sample')
x = np.linspace(2.5, 5.5, 100)
var = mu**2/(sample_size)
y = np.exp(-(x-mu)**2/(2*var))/np.sqrt(2*np.pi*var)
plt.plot(x, y, label=r'$N(\mu, \sigma)$', c='tomato')
plt.legend()
plt.xlim(3., 5)
plt.savefig('exponential_distribution.png', facecolor='w')
plt.close()
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="exponential_distribution.png" alt="&amp;ldquo;exponential_distribution.png&amp;rdquo;">&lt;/p>
&lt;p>Note na figura acima que o plot para a fun√ß√£o $\frac{e^{-\frac{(x-\mu)^2}{2\sigma^2}}}{\sqrt(2\pi\sigma^2)}$ e o histograma coincidem. Voc√™ pode testar essa coincid√™ncia com outras distribui√ß√µes, o mesmo comportamento se repetira. √â isso que quero dizer com &lt;strong>universalidade&lt;/strong>.&lt;/p>
&lt;p>Um questionamento v√°lido √© que estamos tratando apenas de uma vari√°vel aleat√≥ria e sua amostragem. Mas no mundo real existem outras estruturas mais intricadas. Por exemplo
pegue um conjunto de vari√°veis aleat√≥rias
$\mathcal C=(X_{1 1}, X_{1 2}, \cdots, X_{N N})$, suponha que exista uma certa **simetria** nesse conjunto, uma possibilidade √© $X_{i j} = X_{j i}$.
N√£o √© dif√≠cil imaginar situa√ß√µes onde tal conjunto apare√ßa.&lt;/p>
&lt;p>Podemos armazenar uma realiza√ß√£o de $\mathcal C$ em uma matriz que nada mais √© que um grafo completo com pesos. Ao estudar essas matrizes oriundas desse tipo de amostragem entramos em um novo campo da matem√°tica, o campo das matrizes aleat√≥rias.
Nesse campo de estudos uma amostragem n√£o retorna um n√∫mero, mas sim uma matriz.&lt;/p>
&lt;p>A fun√ß√£o &lt;code>normalRMT&lt;/code> apresentada abaixo √© um gerador de matrizes aleat√≥rias conhecidas como Gaussianas ortogonais.&lt;/p>
&lt;pre>&lt;code class="language-python">def normalRMT(n=100):
&amp;quot;&amp;quot;&amp;quot;Generate a random matrix with normal distribution entries
Args:
n : (int) number of rows and columns
Returns:
m : (numpy.ndarray) random matrix
&amp;quot;&amp;quot;&amp;quot;
std = 1/np.sqrt(2)
m = np.random.normal(size=(n,n), scale=std)
m = (m+m.T)
m /= np.sqrt(n)
return m
np.set_printoptions(precision=3)
print(f'{normalRMT(3)},\n\n{normalRMT(3)}')
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>[[-1.441e+00 -2.585e-01 -1.349e-01]
[-2.585e-01 -2.304e-01 1.166e-03]
[-1.349e-01 1.166e-03 -1.272e+00]],
[[-0.742 0.607 -0.34 ]
[ 0.607 0.678 0.277]
[-0.34 0.277 -0.127]]
&lt;/code>&lt;/pre>
&lt;p>Sabemos que quando estamos trantando de vari√°veis aleat√≥rias o teorema central do limite √© important√≠ssimo. O que voc√™ pode se perguntar agora √©: &lt;strong>Existe um an√°logo para o teorema central do limite para matrizes aleat√≥rias?&lt;/strong>&lt;/p>
&lt;h1 id="2-n√∫cleos-at√¥micos-g√°s-de-n√∫meros-primos-e-universalidade">2-N√∫cleos at√¥micos, g√°s de n√∫meros primos e universalidade&lt;/h1>
&lt;p>Para o bem e para o mal o conhecimento da f√≠sica at√¥mica foi um dos temas mais importantes desenvolvidos pela humanidade. Portanto, n√£o √© de se estranhar que ap√≥s o ano de 1930 iniciou-se uma grande corrida para compreender n√∫cleos at√¥micos pesados e a f√≠sica de n√™utrons [13].&lt;/p>
&lt;p>Para compreender essa nova f√≠sica de n√™utrons era necess√°rio conhecer a organiza√ß√£o do espectro de resson√¢ncia dos n√∫cleos pesados (esse espectro nada mais √© que os autovalores de um operador muito especial). Uma maneira de se fazer isso √© do jeito que muitas das coisas s√£o estudadas na f√≠sica: pegando se uma coisa e jogando na dire√ß√£o da coisa a ser estudada. Essa metodologia experimental torna poss√≠vel amostrar alguns valores poss√≠veis para o espectro. Contudo, acredito que n√£o preciso argumentar que fazer isso naquela √©poca era extremamente dif√≠cil e caro. Poucos centros conseguiam realizar alguns experimentos e ainda com uma resolu√ß√£o muito baixa para obter resultados suficientes para uma compreens√£o adequada dos n√∫cleos. Era preciso uma sa√≠da mais barata e ela foi encontrada. Tal sa√≠da dependeu apenas de f√≠sica-matem√°tica e ma√ßos de papel.&lt;/p>
&lt;p>&lt;img src="frog.png" alt="">&lt;/p>
&lt;p>Dentre os pioneiros que decidiram atacar o problema de n√∫cleos pesados usando matem√°tica temos Eugene Paul Wigner (Nobel de 1963). A grande sacada de Wigner foi perceber que o fato das intera√ß√µes nucleares serem t√£o complicadas e a infinitude de graus de liberdade seria poss√≠vel tentar compreender essas intera√ß√µes como uma amostragem sujeita a certas condi√ß√µes de simetria.[10 , 11]&lt;/p>
&lt;p>&lt;img src="wigner.png" alt="wigner.png">&lt;/p>
&lt;p>Aqui com simetria queremos dizer que as matrizes envolvidas possuem certas restri√ß√µes tais como&lt;/p>
&lt;pre>&lt;code class="language-python">np.assert_equal(A, A.T)
&lt;/code>&lt;/pre>
&lt;p>Na pr√≥xima se√ß√£o veremos qual o impacto dessas restri√ß√µes na distribui√ß√£o de autovalores das matrizes envolvidas.&lt;/p>
&lt;h2 id="2-a-universalidade-e-lei-do---semic√≠rculo">2-a) Universalidade e lei do semic√≠rculo&lt;/h2>
&lt;p>A fun√ß√£o &lt;code>normalRMT&lt;/code> gera uma matriz sim√©trica onde as entradas s√£o extra√≠das de uma distribui√ß√£o normal. A fun√ß√£o &lt;code>laplaceRMT&lt;/code> gera tamb√©m uma matriz sim√©trica, contudo as entradas s√£o amostras de uma distribui√ß√£o de Laplace.&lt;/p>
&lt;pre>&lt;code class="language-python">
def laplaceRMT(n=100):
&amp;quot;&amp;quot;&amp;quot;Generate a random matrix with Laplace distribution
Args:
n : (int) size of the matrix
Returns:
m : (numpy.ndarray) random matrix with Laplace distribution
&amp;quot;&amp;quot;&amp;quot;
# we know that the variance of the laplace distribution is 2*scale**2
scale = 1/np.sqrt(2)
m = np.zeros((n,n))
values = np.random.laplace(size=n*(n-1)//2, scale=scale)
m[np.triu_indices_from(m, k=1)] = values
# copy the upper diagonal to the lower diagonal
m[np.tril_indices_from(m, k=-1)] = values
np.fill_diagonal(m, np.random.laplace(size=n, scale=scale))
m = m/np.sqrt(n)
return m
&lt;/code>&lt;/pre>
&lt;p>As propriedades &lt;strong>universais&lt;/strong> que iremos explorar aqui est√£o ligadas aos autovalores das matrizes que foram amostradas. Como nossas matrizes s√£o sim√©tricas esses autovalores s√£o todos reais.&lt;/p>
&lt;p>Como cada matriz √© diferente os autovalores tamb√©m ser√£o, eles tamb√©m s√£o vari√°veis aleat√≥rias.&lt;/p>
&lt;pre>&lt;code class="language-python">vals_laplace = np.array([
np.linalg.eigh(laplaceRMT(n=100))[0]
for i in range(100)
])
vals_normal = np.array([
np.linalg.eigh(normalRMT(n=100))[0]
for i in range(100)
])
&lt;/code>&lt;/pre>
&lt;p>Na dec√°da de 50 n√£o havia poder computacional
suficiente para realizar investiga√ß√µes n√∫mericas, mas voc√™ pode facilmente investigar como os autovalores se distribuem usando seu computador e gerando os histogramas&lt;/p>
&lt;pre>&lt;code class="language-python">t = 1
x = np.linspace(-2*t, 2*t, 100)
y = np.zeros_like(x)
x0 = x[4*t-x*2&amp;gt;0]
y[4*t-x*2&amp;gt;0] = np.sqrt(4*t-x0**2)/(2*np.pi*t)
plt.figure(facecolor='white')
plt.hist(vals_laplace.flatten(), bins=50,
hatch ='|',
density=True, label='laplace', alpha=.2)
plt.hist(vals_normal.flatten(), bins=50,
hatch ='o',
density=True, label='normal', alpha=.2)
#sns.distplot(vals_laplace, norm_hist=True, label='Laplace')
#sns.distplot(vals_normal, norm_hist=True, label='Normal')
#sns.distplot(vals2, norm_hist=True, label='sample2')
plt.plot(x, y, label='analytical')
plt.xlabel(r'$\lambda$')
plt.ylabel(r'$\rho(\lambda)$')
plt.legend()
plt.savefig('RMT_distribution.png', facecolor='w')
plt.close()
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="RMT_distribution.png" alt="">&lt;/p>
&lt;p>Veja na figura acima que a distribui√ß√£o de autovalores de matrizes sim√©tricas relacionadas com a distribui√ß√£o normal e de Laplace coincidem. O que estamos vendo aqui √© uma propriedade &lt;strong>universal&lt;/strong>! Espero que voc√™ acredite em mim, mas dado que voc√™ tenha uma matriz aleat√≥ria sim√©trica, quadrada e se as entradas s√£o $i.i.d.$ a distribui√ß√£o de autovalores seguem o que √© conhecido como lei de semic√≠rculo de Wigner. Se a m√©dia e vari√¢ncia das entradas da matriz s√£o $0$ e $1$ respectivamente, ent√£o tal lei tem a seguinte express√£o para a distribui√ß√£o de probabilidade dos autovalores
$$
\rho(\lambda) = \begin{cases}
\frac{\sqrt{4-\lambda^2}}{(2\pi)} \textrm{ se } 4-\lambda^2 \leq 0\newline
0 \textrm{ caso contr√°rio.}
\end{cases}
$$&lt;/p>
&lt;p>Se trocarmos as simetrias, restri√ß√µes ou formato (&lt;code>array.shape[0]!=array.shape[1]&lt;/code>) das matrizes podemos encontrar varia√ß√µes da distribui√ß√£o apresentada acima. Exemplo se a matriz √© complexa mas Hermitiana, ou se √© &amp;ldquo;retangular&amp;rdquo; e real tal como algums matrizes que s√£o usadas para otimizar carteiras de investimento. A pr√≥xima se√ß√£o mostrar√° um caso com outro formato para universalidade.&lt;/p>
&lt;h2 id="2-b-repuls√£o-entre-n√∫meros-primos">2-b) Repuls√£o entre n√∫meros primos&lt;/h2>
&lt;p>Inciamos nosso texto falando sobre como a teoria de matrizes aleat√≥rias floreceu com os estudos estat√≠sticos de n√∫cleos at√¥micos pesados, especificamente nos trabalhos de Wigner. Embora tenha essa origem, muitas vezes ferramentas matem√°ticas desenvolvidas apenas por motiva√ß√µes pr√°ticas alcan√ßam outros ramos da matem√°tica. Brevemente discutirei aqui alguns pontos e rela√ß√µes com uma das conjecturas mais famosas da matem√°tica: a hip√≥tese de Riemann.&lt;/p>
&lt;p>Qualquer pessoa com alguma curiosidade sobre matem√°tica j√° ouviu falar sobre a hip√≥tese de Riemann. Essa hip√≥tese estabele uma rela√ß√£o entre os zeros da fun√ß√£o zeta de Riemann e a distribui√ß√£o de n√∫meros primos. Dada sua import√¢ncia os maiores ci√™ntistas do s√©culo XX se debru√ßaram sobre ela almejando a imortalidade. Um desses ci√™ntistas foi Hugh Montgomery[4].&lt;/p>
&lt;p>Por volta de 1970 Montgomery notou que os zeros da fun√ß√£o zeta tinham uma certa propriedade cuirosa, pareciam repelir uns aos outros. Uma express√£o foi obtidada, que √© a seguinte&lt;/p>
&lt;p>$$
1 - \left( \frac{\sin (\pi u)}{\pi u}\right)^2 + \delta(u)
$$&lt;/p>
&lt;p>N√£o se preocupe em entender a express√£o acima, ela est√° aqui apenas for motivos est√©ticos.
O que importa √© que ela √© simples, t√£o simples que quando Freeman Dyson - um dos gigantes da f√≠sica-matem√°tica - colocou os olhos sobre tal equa√ß√£o ele notou imediatamente que tal equa√ß√£o era id√™ntica a obtida no contexto de matrizes aleat√≥rias Hermitianas (uma matriz √© hermitiana se ela √© igual a sua transporta conjugada) utilizadas para compreender o comportamento de n√∫cleos de √°tomos pesados, tais como ur√¢nio. A imagem abaixo √© uma carta escrita por Dyson.&lt;/p>
&lt;p>&lt;img src="carta.png" alt="">&lt;/p>
&lt;p>As conex√£o entre um ferramental desenvolvido para estudar n√∫cleos at√¥micos e n√∫meros primos era realmente inesperada e talvez seja um dos caminhos para a prova da hipotese de Riemann[5, 2]. Contudo deixemos a hist√≥ria de lado, e voltemos ao ponto principal que √© te dar outro exemplo de universalidade.&lt;/p>
&lt;p>Lembra que Montgomery disse que parecia haver uma repuls√£o entre os zeros da fun√ß√£o Zeta? O que seria esse conceito de repuls√£o em matrizes aleat√≥rias? Vamos checar numericamente&lt;/p>
&lt;p>Voltaremos a usar nossas matrizes aleat√≥rias geradas por distribui√ß√µes Gaussianas e Laplacianas. Usando o mesmo conjunto de autovalores que obtivemos anteriormente iremos calular o espa√ßamento entre cada par de autovalores para cada realiza√ß√£o de uma matriz aleat√≥ria. √â bem f√°cil, basta chamar a fun√ß√£o &lt;code>diff&lt;/code> do numpy&lt;/p>
&lt;pre>&lt;code class="language-python">diff_laplace = np.diff(vals_laplace, axis=1)
diff_normal = np.diff(vals_normal, axis=1)
&lt;/code>&lt;/pre>
&lt;p>Agora o que faremos √© estimar a densidade de probabilidade usnado KDE. Mas antes disso aqui vai uma dica:&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Evite o KDE do sklearn no seu dia a dia, a implementa√ß√£o √© lenta e n√£o flexiv√©l. Dif√≠cilmente voc√™ conseguir√° bons resultados com milh√µes de pontos. Aqui vou usar uma implementa√ß√£o de KDE mais eficiente voc√™ pode instalar ela execuntando o comando abaixo&lt;/strong>&lt;/p>
&lt;/blockquote>
&lt;pre>&lt;code class="language-python">!pip install KDEpy
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-python">from KDEpy import FFTKDE
estimator_normal = FFTKDE( bw='silverman').fit(diff_normal.flatten())
x_normal, probs_normal = estimator_normal.evaluate(100)
mu_normal = np.mean(diff_normal, axis=1).mean()
estimator_laplace = FFTKDE( bw='silverman').fit(diff_laplace.flatten())
x_laplace, probs_laplace = estimator_laplace.evaluate(100)
mu_laplace = np.mean(diff_laplace, axis=1).mean()
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-python">goe_law = lambda x: np.pi*x*np.exp(-np.pi*x**2/4)/2
spacings = np.linspace(0, 4, 100)
p_s = goe_law(spacings)
plt.plot(spacings, p_s, label=r'GOE anal√≠tico', c='orange', linestyle='--')
plt.plot(
x_normal/mu_normal,
probs_normal*mu_normal,
linestyle=':',
linewidth=2,
zorder=1,
label='normal', c='black')
plt.plot(x_laplace/mu_laplace, probs_laplace*mu_laplace, zorder=2,
linestyle='--', label='laplace', c='tomato')
plt.legend()
plt.savefig('RMT_diff_distribution.png', facecolor='w')
plt.close()
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="RMT_diff_distribution.png" alt="">&lt;/p>
&lt;p>O que as distribui√ß√µes acima dizem √© que dado sua matriz ser $i.i.d.$ quadrada e sim√©trica ent√£o a probabilidade que voc√™ encontre dois autovalores iguais √© $0$ (zero). Al√©m do mais, existe um ponto de m√°ximo global em rela√ß√£o a distribui√ß√£o de espa√ßamentos. Esse comportamento que balanceia repuls√£o e atra√ß√£o dos autovalores lembra o comportamento de part√≠culas em um flu√≠do. N√£o √© de espantar que o m√©todo matem√°tico desenvolvido por Wigner para compreender tais matrizes foi denominado G√°s de Coloumb[2].&lt;/p>
&lt;p>Agora que voc√™ tem pelo menos uma ideia do que seria essa repuls√£o para o caso que j√° abordamos (matrizes sim√©tricas quadradas) voltemos ao problema dos n√∫meros primos.&lt;/p>
&lt;p>O comando a seguir baixa os primeiros 100k zeros da fun√ß√£o zeta&lt;/p>
&lt;pre>&lt;code class="language-python">!wget http://www.dtc.umn.edu/~odlyzko/zeta_tables/zeros1
&lt;/code>&lt;/pre>
&lt;p>Um pequeno preprocessamento dos dados:&lt;/p>
&lt;pre>&lt;code class="language-python">zeros = []
with open('zeros1', 'r') as f:
for line in f.readlines():
# remove all spaces in the line and convert it to a float
zeros.append(float(line.replace(' ', '')))
zeta_zeros = np.array(zeros)
&lt;/code>&lt;/pre>
&lt;p>Iremos calcular os espa√ßamentos entre os zeros, a m√©dia de tais espa√ßamento e executar um KDE&lt;/p>
&lt;pre>&lt;code class="language-python">from KDEpy import FFTKDE
diff_zeta = np.diff(zeta_zeros[10000:])
m = np.mean(diff_zeta)
estimator = FFTKDE( bw='silverman').fit(diff_zeta)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-python">x, probs = estimator.evaluate(100)
p = np.pi
goe_law = lambda x: p*x*np.exp(-p*x**2/4)/2
def gue(xs):
arg = -4/np.pi*np.power(xs,2)
vals = 32/np.pi**2*xs**2*np.exp(arg)
return vals
spacings = np.linspace(0, 4, 100)
p_s = gue(spacings)
p_s2 = goe_law(spacings)
plt.plot(x/m, probs*m, label='zeros zeta', linestyle='--')
plt.plot(spacings, p_s, label=r'GUE anal√≠tico', c='blue', linestyle='-.')
plt.plot(spacings, p_s2, label=r'GOE analitico', c='orange', linestyle='-.')
plt.xlim(-0.1, 4)
plt.legend()
plt.savefig('zeta.png', facecolor='w')
plt.close()
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="zeta.png" alt="">&lt;/p>
&lt;p>Veja que a propriedade de repuls√£o apareceu novamente. Note que dentro do plot eu coloquei uma outra curva &lt;code>GOE anal√≠tico&lt;/code>, essa curva √© aquela que melhor descreve a distribui√ß√£o de espa√ßamentos quando suas matrizes aleat√≥rias s√£o sim√©tricas. Isso √© uma li√ß√£o importante aqui e resalta o que eu j√° disse anteriormente. N√£o temos apenas &lt;em>&amp;ldquo;um limite central para matrizes aleat√≥rias&lt;/em>&amp;rdquo;, mas todo um &lt;strong>zool√≥gico que mudar√° dependendo do tipo do seu problema.&lt;/strong>.&lt;/p>
&lt;h1 id="3-usando-rmt-para-encontrar-e-filtrar-ru√≠dos-em-matrizes">3-Usando &lt;em>RMT&lt;/em> para encontrar e filtrar ru√≠dos em matrizes&lt;/h1>
&lt;p>Na se√ß√£o 1 relembramos o resultado do teorema central do limite. Na se√ß√£o 2 foi mostrado que devemos ter em mente as simetrias e restri√ß√µes do nosso problema para analisar qual regra de universalidade √© respeitada. Isto √©: a depender da simetria e restri√ß√µes das nossas matrizes temos um outro &amp;ldquo;&lt;em>timbre de universalidade&lt;/em>&amp;rdquo;.&lt;/p>
&lt;p>Um exemplo de outro timbre surge no espectro de matrizes de correla√ß√£o; matrizes que s√£o comumente utilizadas para an√°lise de carteiras de investimento. Tais matrizes tem &lt;strong>pelo menos a seguinte estrutura&lt;/strong>:&lt;/p>
&lt;p>$$
\mathbf C = \mathbf X \mathbf X^T
$$
onde $\mathbf X$ √© uma matriz real $N\times M$ e $M&amp;gt;N$.&lt;/p>
&lt;p>O c√≥digo abaixo permite explorar em um exemplo o espectro de matrizes aleat√≥rias $N\neq M$ com entradas dadas pela distribui√ß√£o normal.&lt;/p>
&lt;pre>&lt;code class="language-python">def get_marchenko_bounds(Q, sigma=1):
&amp;quot;&amp;quot;&amp;quot;Computes the Marchenko bounds for a given Q and sigma.
Args:
Q : (float) The Q-value.
sigma : (float) The std value.
Returns:
(float, float): The lower and upper bounds for the eigenvalues.
&amp;quot;&amp;quot;&amp;quot;
QiSqrt = np.sqrt(1/Q)
lp = np.power(sigma*(1 + QiSqrt),2)
lm = np.power(sigma*(1 - QiSqrt),2)
return lp, lm
def marchenko_pastur(l, Q, sigma=1):
&amp;quot;&amp;quot;&amp;quot;Return the probability of a Marchenko-Pastur distribution for
a given Q , sigma and eigenvalue.
Args:
l : (float) The eigenvalue.
Q : (float) The Q-value.
sigma : (float) The std value.
Returns:
(float): The probability
&amp;quot;&amp;quot;&amp;quot;
lp, lm = get_marchenko_bounds(Q, sigma)
# outside the interval [lm, lp]
if l &amp;gt; lp or l &amp;lt; lm:
return 0
return (Q/(2*np.pi*sigma*sigma*l))*np.sqrt((lp-l)*(l-lm))
def plot_marchenko_pastur(ax, eigen_values, Q, sigma=1, bins=100, just_the_bulk=False):
&amp;quot;&amp;quot;&amp;quot;Plots the Marchenko-Pastur distribution for a given Q and sigma
Args:
ax : (matplotlib.axes) The axes to plot on.
eigen_values : (np.array) The eigenvalues.
Q : (float) : The Q-value.
sigma : (float) std
bins : (int) The number of bins to use.
just_the_bulk : (bool) If True, only the eigenvalues inside of
the Marchenko-Pastur bounds are plotted.
&amp;quot;&amp;quot;&amp;quot;
l_max, l_min = get_marchenko_bounds(Q, sigma)
eigenvalues_points = np.linspace(l_min, l_max, 100)
pdf = np.vectorize(lambda x : marchenko_pastur(x, Q, sigma))(eigenvalues_points)
if just_the_bulk:
eigen_values = eigen_values[ (eigen_values &amp;lt; l_max)]
ax.plot(eigenvalues_points, pdf, color = 'r', label='Marchenko-Pastur')
ax.hist(eigen_values, label='sample', bins=bins , density=True)
ax.set_xlabel(r&amp;quot;$\lambda$&amp;quot;)
ax.set_ylabel(r&amp;quot;$\rho$&amp;quot;)
ax.legend()
N = 1000
T = 4000
Q = T/N
X = np.random.normal(0,1,size=(N,T))
cor = np.corrcoef(X)
vals = np.linalg.eigh(cor)[0]
fig, ax = plt.subplots(1,1)
plot_marchenko_pastur(ax, vals, Q, sigma=1, bins=100)
plt.legend()
plt.savefig('Marchenko_Pastur.png', facecolor='w')
plt.close()
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="Marchenko_Pastur.png" alt="">&lt;/p>
&lt;p>A fun√ß√£o em vermelho na figura acima √© a &lt;strong>universalidade&lt;/strong> que aparece em matrizes com a restri√ß√£o $N\times M$ e entradas $i.i.d.$ e m√©dia $0$. Tal &lt;strong>universalidade&lt;/strong> tem como formato a distribui√ß√£o de Marchenko-Pastur que √© dada por&lt;/p>
&lt;p>$$
\rho (\lambda) = \frac{Q}{2\pi \sigma^2}\frac{\sqrt{(\lambda_{\max} - \lambda)(\lambda - \lambda_{\min})}}{\lambda}
$$
onde
$$
\lambda_{\max,\min} = \sigma^2(1 \pm \sqrt{\frac{1}{Q}})^2.
$$&lt;/p>
&lt;p>Note os par√¢metros como $Q$ e $\sigma$. Tais par√¢metros precisam ser ajustados para obter um melhor fit com dados reais.&lt;/p>
&lt;p>Agora iremos para um caso real. Vamos usar dados obtidos via Yahoo Finance com a biblioteca &lt;code>yfinance&lt;/code> para consturir uma matriz de correla√ß√£o com dados de ativos financeiros&lt;/p>
&lt;pre>&lt;code class="language-python"># voc√™ precisa desse pacote para baixar os dados
!pip install yfinance
&lt;/code>&lt;/pre>
&lt;p>Isso aqui √© um post bem informal, ent√£o peguei peguei uma lista aleat√≥ria com alguns tickers que encontrei na internet&lt;/p>
&lt;pre>&lt;code class="language-python">
!wget https://raw.githubusercontent.com/shilewenuw/get_all_tickers/master/get_all_tickers/tickers.csv
&lt;/code>&lt;/pre>
&lt;p>selecionei apenas 500 para evitar que o processo de download seja muito demorado&lt;/p>
&lt;pre>&lt;code class="language-python">tickers = np.loadtxt('tickers.csv', dtype=str, delimiter=',').tolist()
tickers = np.random.choice(tickers, size=500, replace=False).tolist()
&lt;/code>&lt;/pre>
&lt;p>vamos baixar agora os dados em um peri√≥do espec√≠fico&lt;/p>
&lt;pre>&lt;code class="language-python">
import yfinance as yf
df = yf.download (tickers,
start=&amp;quot;2017-01-01&amp;quot;, end=&amp;quot;2019-10-01&amp;quot;,
interval = &amp;quot;1d&amp;quot;,
group_by = 'ticker',
progress = True)
&lt;/code>&lt;/pre>
&lt;p>o &lt;code>yfinance&lt;/code> vai gerar um dataframe com multiindex, ent√£o precisamos separar da
forma que queremos&lt;/p>
&lt;pre>&lt;code class="language-python">
tickers_available = list(set([ ticket for ticket, _ in df.columns.T.to_numpy()]))
prices = pd.DataFrame()
for ticker in tickers_available:
try:
prices[ticker] = df[(ticker, 'Adj Close')]
except KeyError:
pass
&lt;/code>&lt;/pre>
&lt;p>Agora iremos calcular o retorno. Aqui entra um ponto delicado. Voc√™ poder√° achar alguns posts na internet ou mesmo artigos argumentando que √© necess√°rio calcular o retorno como
$\log (r+1)$ pois assim as entradas da sua matriz seguir√° uma distribui√ß√£o normal o que permitir√° a aplica√ß√£o de RMT. J√° vimos no presente texto que n√£o precisamos que as entradas da matrizes venham de uma distribui√ß√£o normal para que a &lt;strong>universalidade&lt;/strong> apare√ßa. A escolha ou n√£o de usar $\log$ nos retornos merece mais aten√ß√£o, inclusive com cr√≠ticas em rela√ß√£o ao uso[6, 7, 8]. Mas esse post n√£o pretende te vender nada, por isso vou ficar com o mais simples.&lt;/p>
&lt;pre>&lt;code class="language-python"># calculamos os retornos
returns_all = prices.pct_change()
# a primeira linha n√£o faz sentido, n√£o existe retorno no primeiro dia
returns_all = returns_all.iloc[1:, :]
# vamos limpar todas as linhas se mnegocia√ß√£o e dropar qualquer coluna com muitos NaN
returns_all.dropna(axis = 1, thresh=len(returns_all.index)/2, inplace=True)
returns_all.dropna(axis = 0, inplace=True)
# seleciona apenas 150 colunas
returns_all = returns_all[np.random.choice(returns_all.columns, size=120, replace=False)]
#returns_all = returns_all.iloc[150:]
&lt;/code>&lt;/pre>
&lt;p>Com o &lt;code>df&lt;/code> pronto calcularemos a matriz de correla√ß√£o e seus autovalores&lt;/p>
&lt;pre>&lt;code class="language-python">correlation_matrix = returns_all.interpolate().corr()
vals = np.linalg.eigh(correlation_matrix.values)[0]
&lt;/code>&lt;/pre>
&lt;p>Vamos usar os par√¢metros padr√µes para $Q$ e $\sigma$ e torcer para que funcione&lt;/p>
&lt;pre>&lt;code class="language-python">
T, N = returns_all.shape
Q=T/N
sigma= 1
fig, ax = plt.subplots(1,1)
plot_marchenko_pastur(ax, vals, Q, sigma=1, bins=200, just_the_bulk=False)
plt.legend()
plt.savefig('Marchenko_Pastur_all.png', facecolor='w')
plt.close()
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="Marchenko_Pastur_all.png" alt="">&lt;/p>
&lt;p>Usando todo o intervalo de tempo do nosso &lt;code>df&lt;/code> obtivemos o que parece um ajuste razo√°vel. √â claro que voc√™ poderia (deveria) rodar algum teste estatistico para verificar tal ajuste.
Existem alguns trabalhos que fizeram essa an√°lise de forma rigorosa, comparando mercados e peri√≥dos espec√≠ficos em rela√ß√£o a distribui√ß√£o de Marchenko-Pastur[9].&lt;/p>
&lt;p>Se voc√™ for uma pessoa atenta notar√° que na imagem acima existem alguns autovalores fora do suporte da Marchenko-Pastur. A ideia de filtragem via RMT √© como dito em [9] testar seus dados em rela√ß√£o a &amp;ldquo;&lt;em>hip√≥tese nula&lt;/em>&amp;rdquo; da RMT. No caso se seus autovalores est√£o dentro do &lt;em>bulk&lt;/em> da distribui√ß√£o que descreve um modelo de entradas &lt;em>i.i.d.&lt;/em>.&lt;/p>
&lt;p>Como isso foi aplicado em alguns trabalhos? Vamos ver na pr√°tica.&lt;/p>
&lt;p>Usaremos $70$% da s√©rie hist√≥rica para calcular uma nova matriz de correla√ß√£o. Com a matriz de correla√ß√£o em m√£os vamos computar os autovalores e autovetores.&lt;/p>
&lt;pre>&lt;code class="language-python"># iremos usar 70% da serie para realizar a filtragem
returns_all.shape[0]*0.70
n_days = returns_all.shape[0]
n_days_in = int(n_days*(1-0.70))
returns = returns_all.copy()
sample = returns.iloc[:(returns.shape[0]-n_days_in), :].copy()
correlation_matrix = sample.interpolate().corr()
vals, vecs = np.linalg.eigh(correlation_matrix.values)
&lt;/code>&lt;/pre>
&lt;p>Os autovalores e autovetores podem ser compreendidos como a decomposi√ß√£o de uma dada matriz.
Portanto, o seguinte teste precisa passar&lt;/p>
&lt;pre>&lt;code class="language-python"> assert np.abs(
np.dot(vecs, np.dot(np.diag(vals), np.transpose(vecs))).flatten()
- correlation_matrix.values.flatten()
).max() &amp;lt; 1e-10
&lt;/code>&lt;/pre>
&lt;p>A distribui√ß√£o de Marchenko-Pastur serve como um indicativo para nossa filtragem. O que faremos √© jogar fora todos os autovalores
que est√£o dentro da distribui√ß√£o de Marchenko-Pastur, posteriormente reconstruiremos a matriz de correla√ß√£o.&lt;/p>
&lt;pre>&lt;code class="language-python">T, N = returns.shape
Q=T/N
sigma = 1
lp, lm = get_marchenko_bounds(Q, sigma)
# Filter the eigenvalues out
vals[vals &amp;lt;= lp ] = 0
# Reconstruct the matrix
filtered_matrix = np.dot(vecs, np.dot(np.diag(vals), np.transpose(vecs)))
np.fill_diagonal(filtered_matrix, 1)
&lt;/code>&lt;/pre>
&lt;p>Com a matriz de correla√ß√£o filtrada voc√™ pode fazer o que bem entender com ela - existem outras maneiras de se realizar uma filtragem - uma das poss√≠veis aplica√ß√µes que precisa ser utilizada com cuidado √© usar tal matriz filtrada como input para algoritmos de otimiza√ß√£o de carteira. Talvez fa√ßa um outro post descrevendo essa otimiza√ß√£o de forma mais clara, mas esse n√£o √© meu enfoque nesse post e nem minha especialidade. Portanto, se voc√™ quiser dar uma lida recomendo os seguintes posts: [17, 18]&lt;/p>
&lt;p>O que voc√™ precisa saber √© que uma matriz de covari√¢ncia, $\mathbf C_\sigma$, adimite uma decomposi√ß√£o em rela√ß√£o a matriz de correla√ß√£o atr√°ves da seguinte forma&lt;/p>
&lt;p>$$
\mathbf C_\sigma = \mathbf D^{-1/2} \mathbf C \mathbf D^{-1/2}
$$
onde $\mathbf D^{-1/2}$ √© uma matriz diagonal com as entradas sendo os desvios padr√£o para cada serie de dados, isto √©&lt;br>
$$
\begin{bmatrix}
\sigma_{1} &amp;amp;0 &amp;amp;\cdots &amp;amp;0 \&lt;br>
0 &amp;amp;\sigma_{2} &amp;amp;\cdots &amp;amp;0 \&lt;br>
\vdots &amp;amp;\vdots &amp;amp;\ddots &amp;amp;\vdots \&lt;br>
0 &amp;amp;0 &amp;amp;\cdots &amp;amp;\sigma_{M} \end{bmatrix}
$$&lt;/p>
&lt;p>Discutimos uma maneira de obter uma matriz de correla√ß√£o filtrada, $\mathbf{\tilde C}$, atrav√©s de RMT,
a ideia √© plugar essa nova matriz na equa√ß√£o anterior e obter uma nova matriz de covari√¢ncia onde as informa√ß√µes menos relevantes foram eliminadas.&lt;/p>
&lt;p>$$
\mathbf{\tilde C_\sigma} = \mathbf D^{-1/2} \mathbf{\tilde C} \mathbf D^{-1/2}.
$$&lt;/p>
&lt;p>Tendo essa nova matriz de cov√¢riancia filtrada agora basta voc√™ ingerir ela em algum m√©todo preferido para otimiza√ß√£o e comparar com o resultado obtido usando a matriz original. Aqui usaremos o cl√°ssico Markowitz&lt;/p>
&lt;pre>&lt;code class="language-python"># Reconstruct the filtered covariance matrix
covariance_matrix = sample.cov()
inv_cov_mat = np.linalg.pinv(covariance_matrix)
# Construct minimum variance weights
ones = np.ones(len(inv_cov_mat))
inv_dot_ones = np.dot(inv_cov_mat, ones)
min_var_weights = inv_dot_ones/ np.dot( inv_dot_ones , ones)
variances = np.diag(sample.cov().values)
standard_deviations = np.sqrt(variances)
D = np.diag(standard_deviations)
filtered_cov = np.dot(D ,np.dot(filtered_matrix,D))
filtered_cov = filtered_matrix
filtered_cov = (np.dot(np.diag(standard_deviations),
np.dot(filtered_matrix,np.diag(standard_deviations))))
filt_inv_cov = np.linalg.pinv(filtered_cov)
# Construct minimum variance weights
ones = np.ones(len(filt_inv_cov))
inv_dot_ones = np.dot(filt_inv_cov, ones)
filt_min_var_weights = inv_dot_ones/ np.dot( inv_dot_ones , ones)
def get_cumulative_returns_over_time(sample, weights):
weights[weights &amp;lt;= 0 ] = 0
weights = weights / weights.sum()
return (((1+sample).cumprod(axis=0))-1).dot(weights)
cumulative_returns = get_cumulative_returns_over_time(returns, min_var_weights).values
cumulative_returns_filt = get_cumulative_returns_over_time(returns, filt_min_var_weights).values
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-python">
in_sample_ind = np.arange(0, (returns.shape[0]-n_days_in+1))
out_sample_ind = np.arange((returns.shape[0]-n_days_in), returns.shape[0])
f = plt.figure()
ax = plt.subplot(111)
points = np.arange(0, len(cumulative_returns))[out_sample_ind]
ax.plot(points, cumulative_returns[out_sample_ind], 'orange', linestyle='--', label='original')
ax.plot(points, cumulative_returns_filt[out_sample_ind], 'b', linestyle='-.', label='filtrado')
ymax = max(cumulative_returns[out_sample_ind].max(), cumulative_returns_filt[out_sample_ind].max())
ymin = min(cumulative_returns[out_sample_ind].min(), cumulative_returns_filt[out_sample_ind].min())
plt.legend()
plt.savefig('comp.png', facecolor='w')
plt.close()
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="comp.png" alt="">&lt;/p>
&lt;p>Obtivemos uma melhora, mas novamente ressaltamos que uma analise mais criteriosa deveria ter sido feita. Vamos listar alguns pontos&lt;/p>
&lt;ol>
&lt;li>Em rela√ß√£o a quest√£o da escolha do intervalo de tempo. Isto √©, se o tamanho foi pequeno de mais para capturar a correla√ß√£o ou se foi grande de mais tal que as correla√ß√µes entre ativos n√£o s√£o estacion√°rias.&lt;/li>
&lt;li>O (n√£o) uso do $\log$-retorno e seu impacto&lt;/li>
&lt;li>Uma escolha n√£o aleat√≥ria do que seria analisado&lt;/li>
&lt;li>M√©todos de unfolding dos autovalores (tema para outro post)&lt;/li>
&lt;/ol>
&lt;h1 id="5---vantagens-cr√≠ticas-e-sugest√µes">5 - Vantagens, cr√≠ticas e sugest√µes&lt;/h1>
&lt;p>Voc√™ poder√° encontrar alguns trabalhos e posts descrevendo o uso de matrizes aleat√≥rias para filtragem de matrizes de correla√ß√£o sem uma boa cr√≠tica ou explicita√ß√£o das limita√ß√µes vou linkar aqui alguns pontos positivos e negativos e limita√ß√µes&lt;/p>
&lt;h2 id="onde-realmente-rmt-se-mostrou-√∫til">Onde realmente RMT se mostrou √∫til&lt;/h2>
&lt;ul>
&lt;li>Obviamente a RMT √© indiscutivelmente bem sucedida na matem√°tica e f√≠sica permitindo compreender sistemas apenas analisando a estat√≠stica dos &lt;em>gases matriciais&lt;/em>.&lt;/li>
&lt;li>Em machine learning a RMT tamb√©m est√° provando ser uma ferramenta √∫til para compreender e melhorar o processo de aprendizado [15].&lt;/li>
&lt;li>Entender comportamentos de sistemas sociais, biol√≥gicos e econ√¥micos. Aqui com entender o comportamento digo apenas saber se um dado segue uma caracter√≠stica dada por alguma lei espec√≠fica como a lei de semic√≠rculo. Isto √©, n√£o existe discuss√£o em voc√™ pegar um dado sistema que √© representado por uma matriz, estudar o comportamento do seu espectro de autovalores e autovetores e verificar que seguem algumas lei de universalidade. &lt;strong>Isso √© bem diferente de dizer que se voc√™ filtrar uma matriz de correla√ß√£o via RMT voc√™ ir√° obter sempre resultados melhores.&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h2 id="limita√ß√µes">Limita√ß√µes&lt;/h2>
&lt;ul>
&lt;li>Note que n√£o realizamos nenhum tipo de teste para decidir se realmente a distribui√ß√£o de autovalores era a distribui√ß√£o desejada. Baseamos isso s√≥ no olhometro, obviamente n√£o √© uma boa ideia.&lt;/li>
&lt;li>A filtragem apenas removendo os autovalores apesar de simples √© limitada e pode ser contra produtiva, outros m√©todos de filtragem podem ser inclusive melhores[14]. Inclusive n√£o √© uma das √∫nicas aplica√ß√µes de RMT para tratamento desse tipo de dado [16]&lt;/li>
&lt;/ul>
&lt;h2 id="para-conhecer-mais">Para conhecer mais&lt;/h2>
&lt;h3 id="ci√™ntistas">Ci√™ntistas&lt;/h3>
&lt;ul>
&lt;li>Alguns grandes nomes de RMT: Madan Lal Mehta, Freeman Dyson e Terrence Tao&lt;/li>
&lt;li>Alguns brasileiros: Marcel Novaes autor do livro
&lt;a href="https://link.springer.com/book/10.1007/978-3-319-70885-0" target="_blank" rel="noopener">Introduction to Random Matrices - Theory and Practice&lt;/a>-
&lt;a href="https://arxiv.org/abs/1712.07903" target="_blank" rel="noopener">arxiv&lt;/a>; Fernando Lucas Metz trabalhou com o Nobel Giorgio Parisi.&lt;/li>
&lt;/ul>
&lt;h3 id="encontrou-um-erro-ou-quer-melhorar-esse-texto">Encontrou um erro ou quer melhorar esse texto?&lt;/h3>
&lt;ul>
&lt;li>Fa√ßa sua contribui√ß√£o criando uma
&lt;a href="https://github.com/devmessias/devmessias.github.io/issues/new" target="_blank" rel="noopener">issue&lt;/a> ou um PR editando esse arquivo aqui
&lt;a href="https://github.com/devmessias/devmessias.github.io/blob/master/content/post/random_matrix_theory/index.md" target="_blank" rel="noopener">random_matrix_theory/index.md&lt;/a>.&lt;/li>
&lt;/ul>
&lt;h1 id="6-refer√™ncias">6-Refer√™ncias&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>[1] M. Kac, ‚ÄúCan One Hear the Shape of a Drum?,‚Äù The American Mathematical Monthly, vol. 73, no. 4, p. 1, Apr. 1966, doi: 10.2307/2313748.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[2] Wigner, E.P., 1957. Statistical properties of real symmetric matrices with many dimensions (pp. 174-184). Princeton University.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[4] ‚ÄúFrom Prime Numbers to Nuclear Physics and Beyond,‚Äù Institute for Advanced Study. &lt;a href="https://www.ias.edu/ideas/2013/primes-random-matrices">https://www.ias.edu/ideas/2013/primes-random-matrices&lt;/a> (accessed Sep. 30, 2020).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[5] ‚ÄúGUE hypothesis,‚Äù What‚Äôs new. &lt;a href="https://terrytao.wordpress.com/tag/gue-hypothesis/">https://terrytao.wordpress.com/tag/gue-hypothesis/&lt;/a> (accessed Nov. 22, 2021).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[6] R. Hudson and A. Gregoriou, ‚ÄúCalculating and Comparing Security Returns is Harder than you Think: A Comparison between Logarithmic and Simple Returns,‚Äù Social Science Research Network, Rochester, NY, SSRN Scholarly Paper ID 1549328, Feb. 2010. doi: 10.2139/ssrn.1549328.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[7] A. Meucci, ‚ÄúQuant Nugget 2: Linear vs. Compounded Returns ‚Äì Common Pitfalls in Portfolio Management,‚Äù Social Science Research Network, Rochester, NY, SSRN Scholarly Paper ID 1586656, May 2010. Accessed: Dec. 01, 2021. [Online]. Available: &lt;a href="https://papers.ssrn.com/abstract=1586656">https://papers.ssrn.com/abstract=1586656&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[8] Lidian, ‚ÄúAnalysis on Stocks: Log(1+return) or Simple Return?,‚Äù Medium, Sep. 18, 2020. &lt;a href="https://medium.com/@huangchingchiu/analysis-on-stocks-log-1-return-or-simple-return-371c3f60fab2">https://medium.com/@huangchingchiu/analysis-on-stocks-log-1-return-or-simple-return-371c3f60fab2&lt;/a> (accessed Nov. 25, 2021).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[9] N. A. Eterovic and D. S. Eterovic, ‚ÄúSeparating the Wheat from the Chaff: Understanding Portfolio Returns in an Emerging Market,‚Äù Social Science Research Network, Rochester, NY, SSRN Scholarly Paper ID 2161646, Oct. 2012. doi: 10.2139/ssrn.2161646.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[10] E. P. Wigner, ‚ÄúCharacteristic Vectors of Bordered Matrices With Infinite Dimensions,‚Äù Annals of Mathematics, vol. 62, no. 3, pp. 548‚Äì564, 1955, doi: 10.2307/1970079.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[11] E. P. Wigner, ‚ÄúOn the statistical distribution of the widths and spacings of nuclear resonance levels,‚Äù Mathematical Proceedings of the Cambridge Philosophical Society, vol. 47, no. 4, pp. 790‚Äì798, Oct. 1951, doi: 10.1017/S0305004100027237.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[13] F. W. K. Firk and S. J. Miller, ‚ÄúNuclei, Primes and the Random Matrix Connection,‚Äù Symmetry, vol. 1, no. 1, pp. 64‚Äì105, Sep. 2009, doi: 10.3390/sym1010064.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[14] L. Sandoval, A. B. Bortoluzzo, and M. K. Venezuela, ‚ÄúNot all that glitters is RMT in the forecasting of risk of portfolios in the Brazilian stock market,‚Äù Physica A: Statistical Mechanics and its Applications, vol. 410, pp. 94‚Äì109, Sep. 2014, doi: 10.1016/j.physa.2014.05.006.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[15] M. E. A. Seddik, C. Louart, M. Tamaazousti, and R. Couillet, ‚ÄúRandom Matrix Theory Proves that Deep Learning Representations of GAN-data Behave as Gaussian Mixtures,‚Äù arXiv:2001.08370 [cs, stat], Jan. 2020, Accessed: Dec. 05, 2021. [Online]. Available: &lt;a href="http://arxiv.org/abs/2001.08370">http://arxiv.org/abs/2001.08370&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[16] D. B. Aires, ‚ÄúAn√°lise de crises financeiras brasileiras usando teoria das matrizes aleat√≥rias,‚Äù Universidade Estadual Paulista (Unesp), 2021. Accessed: Dec. 05, 2021. [Online]. Available: &lt;a href="https://repositorio.unesp.br/handle/11449/204550">https://repositorio.unesp.br/handle/11449/204550&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[17] S. Rome, ‚ÄúEigen-vesting II. Optimize Your Portfolio With Optimization,‚Äù Scott Rome, Mar. 22, 2016. &lt;a href="http://srome.github.io//Eigenvesting-II-Optimize-Your-Portfolio-With-Optimization/">http://srome.github.io//Eigenvesting-II-Optimize-Your-Portfolio-With-Optimization/&lt;/a> (accessed Dec. 05, 2021).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[18] ‚Äú11.1 Portfolio Optimization ‚Äî MOSEK Fusion API for Python 9.3.10.‚Äù &lt;a href="https://docs.mosek.com/latest/pythonfusion/case-studies-portfolio.html">https://docs.mosek.com/latest/pythonfusion/case-studies-portfolio.html&lt;/a> (accessed Dec. 05, 2021).&lt;/p>
&lt;/li>
&lt;/ul></description></item></channel></rss>